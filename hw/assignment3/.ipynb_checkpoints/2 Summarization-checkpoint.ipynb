{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xR48gJMpZ4YR"
   },
   "source": [
    "# Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "OmKUsj55Z4YZ"
   },
   "source": [
    "<center><h3>**Welcome to the Summarization Notebook.**</h3></center>\n",
    "\n",
    "In this assignment, you are going to train a neural network to summarize news articles.\n",
    "Your neural network is going to learn from example, as we provide you with (article, summary) pairs.\n",
    "We provide you with a **toy dataset** made of only articles about police related news.\n",
    "Usual datasets can be 20x larger in size, but we have reduced it for computational purposes.\n",
    "\n",
    "You will do this using a Transformer network, from the __[Attention is all you need](http://papers.nips.cc/paper/7181-attention-is-all-you-need.pdf)__ paper.\n",
    "In this assignment you will:\n",
    "- Learn to process text into sub-word tokens, to avoid fixed vocabulary sizes, and UNK tokens.\n",
    "- Implement the key conceptual blocks of a Transformer.\n",
    "- Use a Transformer to read a news article, and produce a summary.\n",
    "- Perform operations on learned word-vectors to examine what the model has learned.\n",
    "\n",
    "    \n",
    "** Before you start **\n",
    "\n",
    "You should read the Attention is all you need paper.\n",
    "We are providing you with skeleton code for the Transformer, but there will have to implement 5 conceptual blocks of the transformer yourself:\n",
    "-  AttentionQKV: the Query, Key, Value attention mechanism at the center of the Transformer\n",
    "- MultiHeadAttention: the multiple heads that enable each input to attend at many places at once.\n",
    "- PositionEmbedding: the sinusoid-based position embedding of the Transformer.\n",
    "- Encoder & Decoder: The encoder (that reads inputs, such as news articles), the decoder (that produces the output summary, one token at a time)\n",
    "- Full Transformer: piecing it all together."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "n6-bMh8kZ4Yc"
   },
   "source": [
    "You should get the dataset from Google Drive, as instructed in the README of the project.\n",
    "\n",
    "All dataset files should be placed in the `dataset/` folder of this assignment.\n",
    "\n",
    "If you are using Google Colab, follow the instructions to mount your Google Drive onto the remote machine."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XmYnZXS1Z4Yi"
   },
   "source": [
    "# Library imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 269
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 11684,
     "status": "ok",
     "timestamp": 1585772774266,
     "user": {
      "displayName": "Keisuke Watanabe",
      "photoUrl": "",
      "userId": "04038047229892014346"
     },
     "user_tz": 420
    },
    "id": "Zq82zGSSaMUB",
    "outputId": "e3d30c8f-55e5-44fa-e313-a04b7dcbb2d9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sentencepiece in /Users/watanabekeisuke/anaconda3/envs/cs182-ass3/lib/python3.6/site-packages (0.1.85)\n",
      "Requirement already satisfied: segtok in /Users/watanabekeisuke/anaconda3/envs/cs182-ass3/lib/python3.6/site-packages (1.5.7)\n",
      "Requirement already satisfied: regex in /Users/watanabekeisuke/anaconda3/envs/cs182-ass3/lib/python3.6/site-packages (from segtok) (2020.2.20)\n"
     ]
    }
   ],
   "source": [
    "!pip install sentencepiece\n",
    "!pip install segtok"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 121
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 37523,
     "status": "ok",
     "timestamp": 1585772807162,
     "user": {
      "displayName": "Keisuke Watanabe",
      "photoUrl": "",
      "userId": "04038047229892014346"
     },
     "user_tz": 420
    },
    "id": "P_RchgQLaO5s",
    "outputId": "cf0a2353-ac5d-4441-d4c4-514734c39de6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
      "\n",
      "Enter your authorization code:\n",
      "··········\n",
      "Mounted at /content/gdrive\n"
     ]
    }
   ],
   "source": [
    "# Getting access to the dataset and the Python files on Google Drive.\n",
    "# You will probably have to give permission.\n",
    "\n",
    "from google.colab import drive\n",
    "drive.mount('/content/gdrive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 12685,
     "status": "ok",
     "timestamp": 1585772819979,
     "user": {
      "displayName": "Keisuke Watanabe",
      "photoUrl": "",
      "userId": "04038047229892014346"
     },
     "user_tz": 420
    },
    "id": "lNuYMkmZZ4Yl",
    "outputId": "a98b5e8b-f6dc-44f6-a967-cd7f74509d91"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow 1.x selected.\n"
     ]
    }
   ],
   "source": [
    "%tensorflow_version 1.x\n",
    "import sentencepiece as spm\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os, sys\n",
    "import json\n",
    "\n",
    "sys.path.insert(0, \"/content/gdrive/My Drive/Colab Notebooks/cs182/CS182_HW03/\") # This enables us to import Python libraries in the folder.\n",
    "\n",
    "from transformer import Transformer\n",
    "import capita\n",
    "\n",
    "root_folder = \"/content/gdrive/My Drive/Colab Notebooks/cs182/CS182_HW03/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EeUiQFBlZ4Yw"
   },
   "outputs": [],
   "source": [
    "# Load the word piece model that will be used to tokenize the texts into\n",
    "# word pieces with a vocabulary size of 10000\n",
    "\n",
    "sp = spm.SentencePieceProcessor()\n",
    "sp.Load(root_folder+\"dataset/wp_vocab10000.model\")\n",
    "\n",
    "vocab = [line.split('\\t')[0] for line in open(root_folder+\"dataset/wp_vocab10000.vocab\", \"r\")]\n",
    "pad_index = vocab.index('#')\n",
    "\n",
    "def pad_sequence(numerized, pad_index, to_length):\n",
    "    pad = numerized[:to_length]\n",
    "    padded = pad + [pad_index] * (to_length - len(pad))\n",
    "    mask = [w != pad_index for w in padded]\n",
    "    return padded, mask"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "heading_collapsed": true,
    "id": "WQrV-Gd1Z4Y7"
   },
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "hidden": true,
    "id": "O64GVTVaZ4Y9"
   },
   "source": [
    "**As in the previous notebook, you do not have to run this section.**\n",
    "\n",
    "\n",
    "We have provided the preprocessing script, so you see how the text is processed. You do not need to edit this code and can skip this section.\n",
    "\n",
    "You will need some of these functions, when you use the Transformer for generation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 230
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 13268,
     "status": "error",
     "timestamp": 1585772820695,
     "user": {
      "displayName": "Keisuke Watanabe",
      "photoUrl": "",
      "userId": "04038047229892014346"
     },
     "user_tz": 420
    },
    "hidden": true,
    "id": "NojDoM5OZ4Y_",
    "outputId": "c728e1ec-1750-4a1e-8ed5-13cd47a35f45"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-371901ff4677>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0moutput_length\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0md\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m     \u001b[0;31m# Tokenize, numerize\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0md\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'input'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEncodeAsIds\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcapita\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreprocess_capitalization\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'story'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'dataset' is not defined"
     ]
    }
   ],
   "source": [
    "# You are not provided with this file, and do not have to run this.\n",
    "# You are provided with this code so you can see how the data was generated from raw text.\n",
    "\n",
    "def pad_sequence(numerized, pad_index, to_length):\n",
    "    pad = numerized[:to_length]\n",
    "    padded = pad + [pad_index] * (to_length - len(pad))\n",
    "    mask = [w != pad_index for w in padded]\n",
    "    return padded, mask\n",
    "\n",
    "input_length = 400\n",
    "output_length = 100\n",
    "\n",
    "for d in dataset:\n",
    "    # Tokenize, numerize\n",
    "    d['input'] = sp.EncodeAsIds(capita.preprocess_capitalization(d['story']))\n",
    "    d['output'] = sp.EncodeAsIds(capita.preprocess_capitalization(d['summary']))\n",
    "    \n",
    "    # Padding    \n",
    "    d['input'], d['input_mask'] =  pad_sequence(d['input'],  pad_index, input_length)\n",
    "    d['output'], d['output_mask'] = pad_sequence(d['output'], pad_index, output_length)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QcW6Bf-GZ4ZI"
   },
   "source": [
    "# Building blocks of a Transformer\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NH1VzsFzZ4ZN"
   },
   "source": [
    "**TODO**:\n",
    "\n",
    "Implement the 5 blocks of the Transformer. In order to finish this section, you should get very small error <1e-7 on each of the 5 checks in this section.\n",
    "\n",
    "\n",
    "The Transformer is split into 3 files: transformer_attention.py, transformer_layers.py and transformer.py\n",
    "\n",
    "Each section below gives you directions and a way to verify your code works properly.\n",
    "\n",
    "You do not need to modify the rest of the code provided, but should read it to understand overall architecture.\n",
    "\n",
    "Our Transformer is built as a Keras model, a standard that is good for you to get accustomed to.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "heading_collapsed": true,
    "id": "RC6QPI_FZ4ZP"
   },
   "source": [
    "## (1) Implementing the Query-Key-Value Attention (AttentionQKV)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "hidden": true,
    "id": "Y6KumvmmZ4ZR"
   },
   "source": [
    "This part is located in AttentionQKV in transformer_attention.py. You must implement the call function of the class.\n",
    "You will need to implement the mathematical procedure of AttentionQKV that is described in the [Attention is all you need paper](https://arxiv.org/pdf/1706.03762.pdf)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "hidden": true,
    "id": "E843VhyNZ4ZU"
   },
   "outputs": [],
   "source": [
    "from transformer_attention import AttentionQKV\n",
    "\n",
    "batch_size = 2;\n",
    "n_queries = 3;\n",
    "n_keyval = 5;\n",
    "depth_k = 2;\n",
    "depth_v = 2\n",
    "\n",
    "with open(root_folder+\"transformer_checks/attention_qkv_io.json\", \"r\") as f:\n",
    "    io = json.load(f)\n",
    "    queries = np.array(io['queries'])\n",
    "    keys = np.array(io['keys'])\n",
    "    values = np.array(io['values'])\n",
    "    expected_output  = np.array(io['output'])\n",
    "    expected_weights = np.array(io['weights'])\n",
    "\n",
    "attn_qkv = AttentionQKV()\n",
    "queries_h = tf.placeholder(tf.float32,shape=(None, n_queries, depth_k), name=\"queries\")\n",
    "keys_h = tf.placeholder(tf.float32,shape=(None, n_keyval, depth_k), name=\"keys\")\n",
    "values_h = tf.placeholder(tf.float32,shape=(None, n_keyval, depth_v), name=\"values\")\n",
    "\n",
    "attn_output, attn_weights = attn_qkv(queries_h, keys_h, values_h)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    output, weights = sess.run([attn_output, attn_weights], feed_dict={queries_h: queries, keys_h: keys, values_h: values})\n",
    "\n",
    "print(\"Total error on the output:\",np.sum(np.abs(expected_output-output)), \"(should be 0.0 or close to 0.0)\")\n",
    "print(\"Total error on the weights:\",np.sum(np.abs(expected_weights-weights)), \"(should be 0.0 or close to 0.0)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "heading_collapsed": true,
    "id": "bBFNSVM5Z4Ze"
   },
   "source": [
    "## (2) Implementing Multi-head attention"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "hidden": true,
    "id": "rLs0pyZSZ4Zg"
   },
   "source": [
    "This part is located in the class MultiHeadProjection in transformer_attention.py.\n",
    "You must implement the call, \\_split_heads, and \\_combine_heads functions.\n",
    "\n",
    "**Procedure**\n",
    "\n",
    "The objective is to leverage the AttentionQKV class you already wrote.\n",
    "\n",
    "Your input are the queries, keys, values as 3-d tensors (batch_size, sequence_length, feature_size).\n",
    "\n",
    "Split them into 4-d tensors (batch_size, n_heads, sequence_length, new_feature_size). Where:\n",
    "$$feature\\_size = n\\_heads * new_feature\\_size.$$\n",
    "\n",
    "You can then feed the split qkv to your implemented AttentionQKV, which will treat each head as an independent attention function.\n",
    "\n",
    "Then the output must be combined back into a 3-d tensor.\n",
    "You can test the validity of your implementation in the cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "hidden": true,
    "id": "CSUJ0IhNZ4Zk"
   },
   "outputs": [],
   "source": [
    "from transformer_attention import MultiHeadProjection\n",
    "\n",
    "batch_size = 2;\n",
    "n_queries = 3;\n",
    "n_heads = 4\n",
    "n_keyval = 5;\n",
    "depth_k = 8;\n",
    "depth_v = 8;\n",
    "\n",
    "with open(root_folder+\"transformer_checks/multihead_io.json\", \"r\") as f:\n",
    "    io = json.load(f)\n",
    "    queries = np.array(io['queries'])\n",
    "    keys = np.array(io['keys'])\n",
    "    values = np.array(io['values'])\n",
    "    expected_output  = np.array(io['output'])\n",
    "\n",
    "attn_qkv = MultiHeadProjection(n_heads)\n",
    "queries_h = tf.placeholder(tf.float32,shape=(None, n_queries, depth_k), name=\"queries\")\n",
    "keys_h = tf.placeholder(tf.float32,shape=(None, n_keyval, depth_k), name=\"keys\")\n",
    "values_h = tf.placeholder(tf.float32,shape=(None, n_keyval, depth_v), name=\"values\")\n",
    "\n",
    "multihead_output = attn_qkv((queries_h, keys_h, values_h))\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    output = sess.run(multihead_output, feed_dict={queries_h: queries, keys_h: keys, values_h: values})\n",
    "\n",
    "print(\"Total error on the output:\",np.sum(np.abs(expected_output-output)), \"(should be 0.0 or close to 0.0)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "heading_collapsed": true,
    "id": "4cewhH6tZ4Zs"
   },
   "source": [
    "## (3) Position Embedding "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "hidden": true,
    "id": "HSxTOWvUZ4Zu"
   },
   "source": [
    "You must implement the PositionEmbedding class in transformer.py.\n",
    "\n",
    "\n",
    "The cell below helps you verify the validity of your implementation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "hidden": true,
    "id": "709fL9mpZ4Zz"
   },
   "outputs": [],
   "source": [
    "from transformer import PositionEmbedding\n",
    "\n",
    "batch_size = 2;\n",
    "sequence_length = 3;\n",
    "dim = 4;\n",
    "\n",
    "with open(root_folder+\"transformer_checks/position_embedding_io.json\", \"r\") as f:\n",
    "    io = json.load(f)\n",
    "    inputs = np.array(io['inputs'])\n",
    "    expected_output  = np.array(io['output'])\n",
    "\n",
    "inputs_h = tf.placeholder(tf.float32,shape=(None, sequence_length, dim), name=\"inputs\")\n",
    "pos_emb = PositionEmbedding()\n",
    "output_t = pos_emb(inputs_h)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    output = sess.run(output_t, feed_dict={inputs_h: inputs})\n",
    "\n",
    "print(\"Total error on the output:\",np.sum(np.abs(expected_output-output)), \"(should be 0.0 or close to 0.0)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "heading_collapsed": true,
    "id": "V9h7L-fQZ4Z8"
   },
   "source": [
    "## (4) Transformer Encoder / Transformer Decoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "hidden": true,
    "id": "Dvvrjd1bZ4Z-"
   },
   "source": [
    "You now have all the blocks needed to implement the Transformer.\n",
    "For this part, you have to fill in 2 classes in the transformer.py file: TransformerEncoderBlock, TransformerDecoderBlock.\n",
    "\n",
    "The code below will verify the accuracy of each block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "hidden": true,
    "id": "3g53-KR1Z4Z_"
   },
   "outputs": [],
   "source": [
    "!ls /content/gdrive\n",
    "from transformer import TransformerEncoderBlock\n",
    "\n",
    "batch_size = 2\n",
    "sequence_length = 5\n",
    "hidden_size = 6\n",
    "filter_size = 12\n",
    "n_heads = 2\n",
    "\n",
    "with open(root_folder+\"transformer_checks/transformer_encoder_block_io.json\", \"r\") as f:\n",
    "    io = json.load(f)\n",
    "    inputs = np.array(io['inputs'])\n",
    "    expected_output = np.array(io['output'])\n",
    "\n",
    "tf.reset_default_graph()\n",
    "inputs_h = tf.placeholder(tf.float32,shape=(None, sequence_length, hidden_size), name=\"inputs\")\n",
    "enc_block = TransformerEncoderBlock(n_heads=n_heads, filter_size=filter_size, hidden_size=hidden_size)\n",
    "output_t = enc_block(inputs_h)\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    saver.restore(sess, root_folder + \"transformer_checks/transformer_encoder_block\")\n",
    "    output = sess.run(output_t, feed_dict={inputs_h: inputs})\n",
    "    \n",
    "print(\"Total error on the output:\",np.sum(np.abs(expected_output-output)), \"(should be 0.0 or close to 0.0)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "hidden": true,
    "id": "h-xq-Ae5Z4aJ"
   },
   "outputs": [],
   "source": [
    "from transformer import TransformerDecoderBlock\n",
    "\n",
    "batch_size = 2\n",
    "encoder_length = 5\n",
    "decoder_length = 3\n",
    "hidden_size = 6\n",
    "filter_size = 12\n",
    "n_heads = 2\n",
    "\n",
    "with open(root_folder + \"transformer_checks/transformer_decoder_block_io.json\", \"r\") as f:\n",
    "    io = json.load(f)\n",
    "    decoder_inputs = np.array(io['decoder_inputs'])\n",
    "    encoder_output = np.array(io['encoder_output'])\n",
    "    expected_output = np.array(io['expected_output'])\n",
    "\n",
    "tf.reset_default_graph()\n",
    "decoder_inputs_h = tf.placeholder(tf.float32,shape=(None, decoder_length, hidden_size), name=\"dec_inputs\")\n",
    "encoder_output_h = tf.placeholder(tf.float32,shape=(None, encoder_length, hidden_size), name=\"enc_out\")\n",
    "\n",
    "dec_block = TransformerDecoderBlock(n_heads=n_heads, filter_size=filter_size, hidden_size=hidden_size)\n",
    "output_t = dec_block(decoder_inputs_h, encoder_output_h)\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    saver.restore(sess, root_folder + \"transformer_checks/transformer_decoder_block\")\n",
    "    output = sess.run(output_t, feed_dict={decoder_inputs_h: decoder_inputs, encoder_output_h: encoder_output})\n",
    "    \n",
    "print(\"Total error on the output:\",np.sum(np.abs(expected_output-output)), \"(should be 0.0 or close to 0.0)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "heading_collapsed": true,
    "id": "52EMYU2oZ4aS"
   },
   "source": [
    "## (5) Transformer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "hidden": true,
    "id": "59W_MK_OZ4aW"
   },
   "source": [
    "This is the final high-level function that pieces it all together.\n",
    "\n",
    "You have to implement the call function of the Transformer class in the `transformer.py` file.\n",
    "\n",
    "The block below verifies your implementation is correct."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "hidden": true,
    "id": "vFYsYyHUZ4aa"
   },
   "outputs": [],
   "source": [
    "from transformer import Transformer\n",
    "\n",
    "batch_size = 2\n",
    "vocab_size = 11\n",
    "n_layers = 3\n",
    "n_heads = 4\n",
    "d_model = 8\n",
    "d_filter = 16\n",
    "input_length = 5\n",
    "output_length = 3\n",
    "\n",
    "with open(root_folder+\"transformer_checks/transformer_io.json\", \"r\") as f:\n",
    "    io = json.load(f)\n",
    "    enc_input = np.array(io['enc_input'])\n",
    "    dec_input = np.array(io['dec_input'])\n",
    "    enc_mask = np.array(io['enc_mask'])\n",
    "    dec_mask = np.array(io['dec_mask'])\n",
    "    expected_output = np.array(io['output'])\n",
    "    \n",
    "tf.reset_default_graph()\n",
    "enc_input_h = tf.placeholder(tf.int32,shape=(None, input_length), name=\"enc_inp\")\n",
    "dec_input_h = tf.placeholder(tf.int32,shape=(None, output_length), name=\"dec_inp\")\n",
    "enc_mask_h = tf.placeholder(tf.bool,shape=(None,input_length),name=\"encoder_mask\")\n",
    "dec_mask_h = tf.placeholder(tf.bool, shape=(None,output_length),name=\"decoder_mask\")\n",
    "\n",
    "transfo = Transformer(vocab_size=vocab_size, n_layers=n_layers, n_heads=n_heads, d_model=d_model, d_filter=d_filter)\n",
    "output_t = transfo(enc_input_h, target_sequence=dec_input_h, encoder_mask=enc_mask_h, decoder_mask=dec_mask_h)\n",
    "\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    saver.restore(sess, root_folder + \"transformer_checks/transformer\")\n",
    "    output = sess.run(output_t, feed_dict={enc_input_h: enc_input, dec_input_h: dec_input, enc_mask_h: enc_mask, dec_mask_h: dec_mask})\n",
    "\n",
    "print(\"Total error on the output:\",np.sum(np.abs(expected_output-output)), \"(should be 0.0 or close to 0.0)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Lo_kykX-Z4ae"
   },
   "source": [
    "# Creating a Transformer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "f4tGWBZ9Z4ag"
   },
   "source": [
    "Now that all the blocks of the Transformer are implemented, we can create a full model with placeholders and a loss.\n",
    "\n",
    "We've helped you with the placeholders, and the loss, as it is similar to the one in the previous assignment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DRMwj5PfZ4ah"
   },
   "outputs": [],
   "source": [
    "# We are giving you the trainer, as it is similar to the one\n",
    "# you created in the Language Modeling assignment.\n",
    "\n",
    "class TransformerTrainer():\n",
    "\n",
    "    def __init__(self, vocab_size, d_model, input_length, output_length, n_layers, d_filter, learning_rate=1e-3, dropout=0):\n",
    "\n",
    "        self.source_sequence = tf.placeholder(tf.int32,shape=(None,input_length), name=\"source_sequence\")\n",
    "        self.target_sequence = tf.placeholder(tf.int32, shape=(None,output_length),name=\"target_sequence\")\n",
    "        self.encoder_mask = tf.placeholder(tf.bool,shape=(None,input_length),name=\"encoder_mask\")\n",
    "        self.decoder_mask = tf.placeholder(tf.bool, shape=(None,output_length),name=\"decoder_mask\")\n",
    "\n",
    "        self.model = Transformer(vocab_size=vocab_size, d_model=d_model, n_layers=n_layers, d_filter=d_filter, dropout=dropout)\n",
    "\n",
    "        self.decoded_logits = self.model(self.source_sequence, self.target_sequence, encoder_mask=self.encoder_mask, decoder_mask=self.decoder_mask)\n",
    "        self.global_step = tf.train.get_or_create_global_step()\n",
    "        \n",
    "        # Summarization loss\n",
    "        self.loss = tf.losses.sparse_softmax_cross_entropy(self.target_sequence, self.decoded_logits, tf.cast(self.decoder_mask, tf.float32))\n",
    "        self.optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate)\n",
    "        self.train_op = self.optimizer.minimize(self.loss, global_step=self.global_step)\n",
    "        self.saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "b6r_LakLZ4as"
   },
   "source": [
    "We now instantiate the Transformer with our sets of hyperparameters specific to the task of summarization.\n",
    "In summarization, we are going to go from documents with up to 400 words, to documents with up to 100 words.\n",
    "The vocabulary size is set for you, and is of 10,000 words (we are using WordPieces, [here is a paper about subword encoding](http://aclweb.org/anthology/P18-1007), if you are interested)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 23542,
     "status": "ok",
     "timestamp": 1585772842844,
     "user": {
      "displayName": "Keisuke Watanabe",
      "photoUrl": "",
      "userId": "04038047229892014346"
     },
     "user_tz": 420
    },
    "id": "ElCJhsD2Z4aw",
    "outputId": "0543411a-f117-4c31-ad06-b5e7118b5c45"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/keras/initializers.py:119: calling RandomUniform.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:Entity <bound method Transformer.call of <transformer.Transformer object at 0x7f9b00609588>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Transformer.call of <transformer.Transformer object at 0x7f9b00609588>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:From /content/gdrive/My Drive/Colab Notebooks/cs182/CS182_HW03/transformer_layers.py:222: The name tf.assert_equal is deprecated. Please use tf.compat.v1.assert_equal instead.\n",
      "\n",
      "WARNING:tensorflow:Entity <bound method TransformerEncoder.call of <transformer.TransformerEncoder object at 0x7f9b00633cc0>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method TransformerEncoder.call of <transformer.TransformerEncoder object at 0x7f9b00633cc0>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method TransformerInputEmbedding.call of <transformer.TransformerInputEmbedding object at 0x7f9b005eb668>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method TransformerInputEmbedding.call of <transformer.TransformerInputEmbedding object at 0x7f9b005eb668>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "WARNING:tensorflow:Entity <bound method PositionEmbedding.call of <transformer.PositionEmbedding object at 0x7f9b00633e10>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <bound method PositionEmbedding.call of <transformer.PositionEmbedding object at 0x7f9b00633e10>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <bound method Stack.call of <transformer_layers.Stack object at 0x7f9b0cdd9588>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Stack.call of <transformer_layers.Stack object at 0x7f9b0cdd9588>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method TransformerEncoderBlock.call of <transformer.TransformerEncoderBlock object at 0x7f9b005fed30>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method TransformerEncoderBlock.call of <transformer.TransformerEncoderBlock object at 0x7f9b005fed30>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:From /content/gdrive/My Drive/Colab Notebooks/cs182/CS182_HW03/transformer_layers.py:36: Layer.add_variable (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `layer.add_weight` method instead.\n",
      "WARNING:tensorflow:Entity <bound method LayerNorm.call of <transformer_layers.LayerNorm object at 0x7f9b0cd7d8d0>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method LayerNorm.call of <transformer_layers.LayerNorm object at 0x7f9b0cd7d8d0>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <transformer_attention.MultiHeadAttention object at 0x7f9b0cd7d9e8>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method MultiHeadAttention.call of <transformer_attention.MultiHeadAttention object at 0x7f9b0cd7d9e8>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method WeightNormDense.call of <transformer_layers.WeightNormDense object at 0x7f9afea123c8>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method WeightNormDense.call of <transformer_layers.WeightNormDense object at 0x7f9afea123c8>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method WeightNormDense.call of <transformer_layers.WeightNormDense object at 0x7f9afea12400>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method WeightNormDense.call of <transformer_layers.WeightNormDense object at 0x7f9afea12400>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method WeightNormDense.call of <transformer_layers.WeightNormDense object at 0x7f9afea12860>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method WeightNormDense.call of <transformer_layers.WeightNormDense object at 0x7f9afea12860>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method MultiHeadProjection.call of <transformer_attention.MultiHeadProjection object at 0x7f9b0cd7db70>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method MultiHeadProjection.call of <transformer_attention.MultiHeadProjection object at 0x7f9b0cd7db70>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method AttentionQKV.call of <transformer_attention.AttentionQKV object at 0x7f9b0cd7dd68>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <bound method AttentionQKV.call of <transformer_attention.AttentionQKV object at 0x7f9b0cd7dd68>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <bound method ApplyAttentionMask.call of <transformer_layers.ApplyAttentionMask object at 0x7f9b0cd7def0>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method ApplyAttentionMask.call of <transformer_layers.ApplyAttentionMask object at 0x7f9b0cd7def0>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:From /content/gdrive/My Drive/Colab Notebooks/cs182/CS182_HW03/transformer_layers.py:189: The name tf.assert_rank_in is deprecated. Please use tf.compat.v1.assert_rank_in instead.\n",
      "\n",
      "WARNING:tensorflow:From /content/gdrive/My Drive/Colab Notebooks/cs182/CS182_HW03/transformer_layers.py:190: The name tf.assert_rank is deprecated. Please use tf.compat.v1.assert_rank instead.\n",
      "\n",
      "WARNING:tensorflow:Entity <bound method WeightNormDense.call of <transformer_layers.WeightNormDense object at 0x7f9afea12f60>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method WeightNormDense.call of <transformer_layers.WeightNormDense object at 0x7f9afea12f60>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method TransformerFeedForward.call of <transformer.TransformerFeedForward object at 0x7f9aff3b8080>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method TransformerFeedForward.call of <transformer.TransformerFeedForward object at 0x7f9aff3b8080>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method LayerNorm.call of <transformer_layers.LayerNorm object at 0x7f9aff3b8240>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method LayerNorm.call of <transformer_layers.LayerNorm object at 0x7f9aff3b8240>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Stack.call of <transformer_layers.DenseStack object at 0x7f9aff3b8358>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Stack.call of <transformer_layers.DenseStack object at 0x7f9aff3b8358>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method TransformerEncoderBlock.call of <transformer.TransformerEncoderBlock object at 0x7f9aff3b8d68>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method TransformerEncoderBlock.call of <transformer.TransformerEncoderBlock object at 0x7f9aff3b8d68>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method LayerNorm.call of <transformer_layers.LayerNorm object at 0x7f9aff3b8f28>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method LayerNorm.call of <transformer_layers.LayerNorm object at 0x7f9aff3b8f28>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <transformer_attention.MultiHeadAttention object at 0x7f9aff3ce080>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method MultiHeadAttention.call of <transformer_attention.MultiHeadAttention object at 0x7f9aff3ce080>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method WeightNormDense.call of <transformer_layers.WeightNormDense object at 0x7f9afe959f98>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method WeightNormDense.call of <transformer_layers.WeightNormDense object at 0x7f9afe959f98>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method WeightNormDense.call of <transformer_layers.WeightNormDense object at 0x7f9afe959c50>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method WeightNormDense.call of <transformer_layers.WeightNormDense object at 0x7f9afe959c50>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method WeightNormDense.call of <transformer_layers.WeightNormDense object at 0x7f9afe959198>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method WeightNormDense.call of <transformer_layers.WeightNormDense object at 0x7f9afe959198>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method MultiHeadProjection.call of <transformer_attention.MultiHeadProjection object at 0x7f9aff3ce208>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method MultiHeadProjection.call of <transformer_attention.MultiHeadProjection object at 0x7f9aff3ce208>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method AttentionQKV.call of <transformer_attention.AttentionQKV object at 0x7f9aff3ce400>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <bound method AttentionQKV.call of <transformer_attention.AttentionQKV object at 0x7f9aff3ce400>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <bound method ApplyAttentionMask.call of <transformer_layers.ApplyAttentionMask object at 0x7f9aff3ce588>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method ApplyAttentionMask.call of <transformer_layers.ApplyAttentionMask object at 0x7f9aff3ce588>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method WeightNormDense.call of <transformer_layers.WeightNormDense object at 0x7f9afe959b70>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method WeightNormDense.call of <transformer_layers.WeightNormDense object at 0x7f9afe959b70>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method TransformerFeedForward.call of <transformer.TransformerFeedForward object at 0x7f9aff3ce6d8>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method TransformerFeedForward.call of <transformer.TransformerFeedForward object at 0x7f9aff3ce6d8>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method LayerNorm.call of <transformer_layers.LayerNorm object at 0x7f9aff3ce898>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method LayerNorm.call of <transformer_layers.LayerNorm object at 0x7f9aff3ce898>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Stack.call of <transformer_layers.DenseStack object at 0x7f9aff3ce9b0>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Stack.call of <transformer_layers.DenseStack object at 0x7f9aff3ce9b0>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method TransformerEncoderBlock.call of <transformer.TransformerEncoderBlock object at 0x7f9aff3d5400>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method TransformerEncoderBlock.call of <transformer.TransformerEncoderBlock object at 0x7f9aff3d5400>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method LayerNorm.call of <transformer_layers.LayerNorm object at 0x7f9aff3d55c0>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method LayerNorm.call of <transformer_layers.LayerNorm object at 0x7f9aff3d55c0>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <transformer_attention.MultiHeadAttention object at 0x7f9aff3d56d8>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method MultiHeadAttention.call of <transformer_attention.MultiHeadAttention object at 0x7f9aff3d56d8>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method WeightNormDense.call of <transformer_layers.WeightNormDense object at 0x7f9afe753908>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method WeightNormDense.call of <transformer_layers.WeightNormDense object at 0x7f9afe753908>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method WeightNormDense.call of <transformer_layers.WeightNormDense object at 0x7f9afe7535c0>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method WeightNormDense.call of <transformer_layers.WeightNormDense object at 0x7f9afe7535c0>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method WeightNormDense.call of <transformer_layers.WeightNormDense object at 0x7f9afe753c50>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method WeightNormDense.call of <transformer_layers.WeightNormDense object at 0x7f9afe753c50>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method MultiHeadProjection.call of <transformer_attention.MultiHeadProjection object at 0x7f9aff3d5860>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method MultiHeadProjection.call of <transformer_attention.MultiHeadProjection object at 0x7f9aff3d5860>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method AttentionQKV.call of <transformer_attention.AttentionQKV object at 0x7f9aff3d5a58>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <bound method AttentionQKV.call of <transformer_attention.AttentionQKV object at 0x7f9aff3d5a58>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <bound method ApplyAttentionMask.call of <transformer_layers.ApplyAttentionMask object at 0x7f9aff3d5be0>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method ApplyAttentionMask.call of <transformer_layers.ApplyAttentionMask object at 0x7f9aff3d5be0>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method WeightNormDense.call of <transformer_layers.WeightNormDense object at 0x7f9afe753278>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method WeightNormDense.call of <transformer_layers.WeightNormDense object at 0x7f9afe753278>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method TransformerFeedForward.call of <transformer.TransformerFeedForward object at 0x7f9aff3d5d30>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method TransformerFeedForward.call of <transformer.TransformerFeedForward object at 0x7f9aff3d5d30>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method LayerNorm.call of <transformer_layers.LayerNorm object at 0x7f9aff3d5ef0>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method LayerNorm.call of <transformer_layers.LayerNorm object at 0x7f9aff3d5ef0>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Stack.call of <transformer_layers.DenseStack object at 0x7f9aff3dc048>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Stack.call of <transformer_layers.DenseStack object at 0x7f9aff3dc048>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method TransformerEncoderBlock.call of <transformer.TransformerEncoderBlock object at 0x7f9aff3dca58>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method TransformerEncoderBlock.call of <transformer.TransformerEncoderBlock object at 0x7f9aff3dca58>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method LayerNorm.call of <transformer_layers.LayerNorm object at 0x7f9aff3dcc18>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method LayerNorm.call of <transformer_layers.LayerNorm object at 0x7f9aff3dcc18>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <transformer_attention.MultiHeadAttention object at 0x7f9aff3dcd30>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method MultiHeadAttention.call of <transformer_attention.MultiHeadAttention object at 0x7f9aff3dcd30>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method WeightNormDense.call of <transformer_layers.WeightNormDense object at 0x7f9afe604da0>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method WeightNormDense.call of <transformer_layers.WeightNormDense object at 0x7f9afe604da0>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method WeightNormDense.call of <transformer_layers.WeightNormDense object at 0x7f9afe604b70>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method WeightNormDense.call of <transformer_layers.WeightNormDense object at 0x7f9afe604b70>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method WeightNormDense.call of <transformer_layers.WeightNormDense object at 0x7f9afe604908>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method WeightNormDense.call of <transformer_layers.WeightNormDense object at 0x7f9afe604908>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method MultiHeadProjection.call of <transformer_attention.MultiHeadProjection object at 0x7f9aff3dceb8>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method MultiHeadProjection.call of <transformer_attention.MultiHeadProjection object at 0x7f9aff3dceb8>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method AttentionQKV.call of <transformer_attention.AttentionQKV object at 0x7f9aff3e40f0>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <bound method AttentionQKV.call of <transformer_attention.AttentionQKV object at 0x7f9aff3e40f0>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <bound method ApplyAttentionMask.call of <transformer_layers.ApplyAttentionMask object at 0x7f9aff3e4278>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method ApplyAttentionMask.call of <transformer_layers.ApplyAttentionMask object at 0x7f9aff3e4278>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method WeightNormDense.call of <transformer_layers.WeightNormDense object at 0x7f9afe604828>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method WeightNormDense.call of <transformer_layers.WeightNormDense object at 0x7f9afe604828>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method TransformerFeedForward.call of <transformer.TransformerFeedForward object at 0x7f9aff3e43c8>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method TransformerFeedForward.call of <transformer.TransformerFeedForward object at 0x7f9aff3e43c8>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method LayerNorm.call of <transformer_layers.LayerNorm object at 0x7f9aff3e4588>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method LayerNorm.call of <transformer_layers.LayerNorm object at 0x7f9aff3e4588>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Stack.call of <transformer_layers.DenseStack object at 0x7f9aff3e46a0>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Stack.call of <transformer_layers.DenseStack object at 0x7f9aff3e46a0>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method TransformerEncoderBlock.call of <transformer.TransformerEncoderBlock object at 0x7f9aff3ea0f0>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method TransformerEncoderBlock.call of <transformer.TransformerEncoderBlock object at 0x7f9aff3ea0f0>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method LayerNorm.call of <transformer_layers.LayerNorm object at 0x7f9aff3ea2b0>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method LayerNorm.call of <transformer_layers.LayerNorm object at 0x7f9aff3ea2b0>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <transformer_attention.MultiHeadAttention object at 0x7f9aff3ea3c8>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method MultiHeadAttention.call of <transformer_attention.MultiHeadAttention object at 0x7f9aff3ea3c8>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method WeightNormDense.call of <transformer_layers.WeightNormDense object at 0x7f9afe4b9278>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method WeightNormDense.call of <transformer_layers.WeightNormDense object at 0x7f9afe4b9278>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method WeightNormDense.call of <transformer_layers.WeightNormDense object at 0x7f9afe4b9e10>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method WeightNormDense.call of <transformer_layers.WeightNormDense object at 0x7f9afe4b9e10>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method WeightNormDense.call of <transformer_layers.WeightNormDense object at 0x7f9afe4b9588>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method WeightNormDense.call of <transformer_layers.WeightNormDense object at 0x7f9afe4b9588>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method MultiHeadProjection.call of <transformer_attention.MultiHeadProjection object at 0x7f9b00609ac8>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method MultiHeadProjection.call of <transformer_attention.MultiHeadProjection object at 0x7f9b00609ac8>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method AttentionQKV.call of <transformer_attention.AttentionQKV object at 0x7f9b00609860>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <bound method AttentionQKV.call of <transformer_attention.AttentionQKV object at 0x7f9b00609860>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <bound method ApplyAttentionMask.call of <transformer_layers.ApplyAttentionMask object at 0x7f9b005fed68>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method ApplyAttentionMask.call of <transformer_layers.ApplyAttentionMask object at 0x7f9b005fed68>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method WeightNormDense.call of <transformer_layers.WeightNormDense object at 0x7f9afe4b9b70>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method WeightNormDense.call of <transformer_layers.WeightNormDense object at 0x7f9afe4b9b70>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method TransformerFeedForward.call of <transformer.TransformerFeedForward object at 0x7f9b0cf12438>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method TransformerFeedForward.call of <transformer.TransformerFeedForward object at 0x7f9b0cf12438>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method LayerNorm.call of <transformer_layers.LayerNorm object at 0x7f9b0066bd68>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method LayerNorm.call of <transformer_layers.LayerNorm object at 0x7f9b0066bd68>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Stack.call of <transformer_layers.DenseStack object at 0x7f9b00655550>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Stack.call of <transformer_layers.DenseStack object at 0x7f9b00655550>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method TransformerEncoderBlock.call of <transformer.TransformerEncoderBlock object at 0x7f9b0dc20160>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method TransformerEncoderBlock.call of <transformer.TransformerEncoderBlock object at 0x7f9b0dc20160>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method LayerNorm.call of <transformer_layers.LayerNorm object at 0x7f9b47efb550>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method LayerNorm.call of <transformer_layers.LayerNorm object at 0x7f9b47efb550>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <transformer_attention.MultiHeadAttention object at 0x7f9b0dc98f60>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method MultiHeadAttention.call of <transformer_attention.MultiHeadAttention object at 0x7f9b0dc98f60>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method WeightNormDense.call of <transformer_layers.WeightNormDense object at 0x7f9afe3e6940>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method WeightNormDense.call of <transformer_layers.WeightNormDense object at 0x7f9afe3e6940>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method WeightNormDense.call of <transformer_layers.WeightNormDense object at 0x7f9afe3e6a90>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method WeightNormDense.call of <transformer_layers.WeightNormDense object at 0x7f9afe3e6a90>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method WeightNormDense.call of <transformer_layers.WeightNormDense object at 0x7f9afe3e6ac8>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method WeightNormDense.call of <transformer_layers.WeightNormDense object at 0x7f9afe3e6ac8>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method MultiHeadProjection.call of <transformer_attention.MultiHeadProjection object at 0x7f9b0dda68d0>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method MultiHeadProjection.call of <transformer_attention.MultiHeadProjection object at 0x7f9b0dda68d0>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method AttentionQKV.call of <transformer_attention.AttentionQKV object at 0x7f9aff3ea588>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <bound method AttentionQKV.call of <transformer_attention.AttentionQKV object at 0x7f9aff3ea588>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <bound method ApplyAttentionMask.call of <transformer_layers.ApplyAttentionMask object at 0x7f9aff3ea710>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method ApplyAttentionMask.call of <transformer_layers.ApplyAttentionMask object at 0x7f9aff3ea710>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method WeightNormDense.call of <transformer_layers.WeightNormDense object at 0x7f9afe3e6f98>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method WeightNormDense.call of <transformer_layers.WeightNormDense object at 0x7f9afe3e6f98>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method TransformerFeedForward.call of <transformer.TransformerFeedForward object at 0x7f9aff3ea860>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method TransformerFeedForward.call of <transformer.TransformerFeedForward object at 0x7f9aff3ea860>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method LayerNorm.call of <transformer_layers.LayerNorm object at 0x7f9aff3eaa20>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method LayerNorm.call of <transformer_layers.LayerNorm object at 0x7f9aff3eaa20>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Stack.call of <transformer_layers.DenseStack object at 0x7f9aff3eab38>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Stack.call of <transformer_layers.DenseStack object at 0x7f9aff3eab38>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method TransformerDecoder.call of <transformer.TransformerDecoder object at 0x7f9b0cdd9780>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <bound method TransformerDecoder.call of <transformer.TransformerDecoder object at 0x7f9b0cdd9780>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <bound method TransformerInputEmbedding.call of <transformer.TransformerInputEmbedding object at 0x7f9b005eb668>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method TransformerInputEmbedding.call of <transformer.TransformerInputEmbedding object at 0x7f9b005eb668>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method PositionEmbedding.call of <transformer.PositionEmbedding object at 0x7f9b00633e10>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <bound method PositionEmbedding.call of <transformer.PositionEmbedding object at 0x7f9b00633e10>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <bound method Stack.call of <transformer_layers.Stack object at 0x7f9aff365940>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Stack.call of <transformer_layers.Stack object at 0x7f9aff365940>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method TransformerDecoderBlock.call of <transformer.TransformerDecoderBlock object at 0x7f9b0cdd9908>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method TransformerDecoderBlock.call of <transformer.TransformerDecoderBlock object at 0x7f9b0cdd9908>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method LayerNorm.call of <transformer_layers.LayerNorm object at 0x7f9b0cdd9b00>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method LayerNorm.call of <transformer_layers.LayerNorm object at 0x7f9b0cdd9b00>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <transformer_attention.MultiHeadAttention object at 0x7f9b0cdd9c18>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method MultiHeadAttention.call of <transformer_attention.MultiHeadAttention object at 0x7f9b0cdd9c18>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method WeightNormDense.call of <transformer_layers.WeightNormDense object at 0x7f9afe1f6940>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method WeightNormDense.call of <transformer_layers.WeightNormDense object at 0x7f9afe1f6940>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method WeightNormDense.call of <transformer_layers.WeightNormDense object at 0x7f9afe1f6c18>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method WeightNormDense.call of <transformer_layers.WeightNormDense object at 0x7f9afe1f6c18>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method WeightNormDense.call of <transformer_layers.WeightNormDense object at 0x7f9afe1f6da0>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method WeightNormDense.call of <transformer_layers.WeightNormDense object at 0x7f9afe1f6da0>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method MultiHeadProjection.call of <transformer_attention.MultiHeadProjection object at 0x7f9b0cdd9da0>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method MultiHeadProjection.call of <transformer_attention.MultiHeadProjection object at 0x7f9b0cdd9da0>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method AttentionQKV.call of <transformer_attention.AttentionQKV object at 0x7f9b0cdd9f98>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <bound method AttentionQKV.call of <transformer_attention.AttentionQKV object at 0x7f9b0cdd9f98>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <bound method ApplyAttentionMask.call of <transformer_layers.ApplyAttentionMask object at 0x7f9aff374160>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method ApplyAttentionMask.call of <transformer_layers.ApplyAttentionMask object at 0x7f9aff374160>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method WeightNormDense.call of <transformer_layers.WeightNormDense object at 0x7f9afe249fd0>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method WeightNormDense.call of <transformer_layers.WeightNormDense object at 0x7f9afe249fd0>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method LayerNorm.call of <transformer_layers.LayerNorm object at 0x7f9b0cdd9b00>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method LayerNorm.call of <transformer_layers.LayerNorm object at 0x7f9b0cdd9b00>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method LayerNorm.call of <transformer_layers.LayerNorm object at 0x7f9b0cdd9b00>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method LayerNorm.call of <transformer_layers.LayerNorm object at 0x7f9b0cdd9b00>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <transformer_attention.MultiHeadAttention object at 0x7f9aff374550>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method MultiHeadAttention.call of <transformer_attention.MultiHeadAttention object at 0x7f9aff374550>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method WeightNormDense.call of <transformer_layers.WeightNormDense object at 0x7f9afe141240>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method WeightNormDense.call of <transformer_layers.WeightNormDense object at 0x7f9afe141240>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method WeightNormDense.call of <transformer_layers.WeightNormDense object at 0x7f9afe141a58>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method WeightNormDense.call of <transformer_layers.WeightNormDense object at 0x7f9afe141a58>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method WeightNormDense.call of <transformer_layers.WeightNormDense object at 0x7f9afe1f9278>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method WeightNormDense.call of <transformer_layers.WeightNormDense object at 0x7f9afe1f9278>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method MultiHeadProjection.call of <transformer_attention.MultiHeadProjection object at 0x7f9aff3746d8>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method MultiHeadProjection.call of <transformer_attention.MultiHeadProjection object at 0x7f9aff3746d8>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method AttentionQKV.call of <transformer_attention.AttentionQKV object at 0x7f9aff3748d0>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <bound method AttentionQKV.call of <transformer_attention.AttentionQKV object at 0x7f9aff3748d0>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <bound method ApplyAttentionMask.call of <transformer_layers.ApplyAttentionMask object at 0x7f9aff374a58>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method ApplyAttentionMask.call of <transformer_layers.ApplyAttentionMask object at 0x7f9aff374a58>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method WeightNormDense.call of <transformer_layers.WeightNormDense object at 0x7f9afe1f9588>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method WeightNormDense.call of <transformer_layers.WeightNormDense object at 0x7f9afe1f9588>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method TransformerFeedForward.call of <transformer.TransformerFeedForward object at 0x7f9aff374ba8>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method TransformerFeedForward.call of <transformer.TransformerFeedForward object at 0x7f9aff374ba8>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method LayerNorm.call of <transformer_layers.LayerNorm object at 0x7f9aff374d68>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method LayerNorm.call of <transformer_layers.LayerNorm object at 0x7f9aff374d68>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Stack.call of <transformer_layers.DenseStack object at 0x7f9aff374e80>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Stack.call of <transformer_layers.DenseStack object at 0x7f9aff374e80>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method TransformerDecoderBlock.call of <transformer.TransformerDecoderBlock object at 0x7f9aff380940>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method TransformerDecoderBlock.call of <transformer.TransformerDecoderBlock object at 0x7f9aff380940>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method LayerNorm.call of <transformer_layers.LayerNorm object at 0x7f9aff380b00>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method LayerNorm.call of <transformer_layers.LayerNorm object at 0x7f9aff380b00>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <transformer_attention.MultiHeadAttention object at 0x7f9aff380c18>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method MultiHeadAttention.call of <transformer_attention.MultiHeadAttention object at 0x7f9aff380c18>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method WeightNormDense.call of <transformer_layers.WeightNormDense object at 0x7f9afe252898>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method WeightNormDense.call of <transformer_layers.WeightNormDense object at 0x7f9afe252898>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method WeightNormDense.call of <transformer_layers.WeightNormDense object at 0x7f9afe2525c0>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method WeightNormDense.call of <transformer_layers.WeightNormDense object at 0x7f9afe2525c0>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method WeightNormDense.call of <transformer_layers.WeightNormDense object at 0x7f9afe2529e8>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method WeightNormDense.call of <transformer_layers.WeightNormDense object at 0x7f9afe2529e8>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method MultiHeadProjection.call of <transformer_attention.MultiHeadProjection object at 0x7f9aff380da0>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method MultiHeadProjection.call of <transformer_attention.MultiHeadProjection object at 0x7f9aff380da0>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method AttentionQKV.call of <transformer_attention.AttentionQKV object at 0x7f9aff380f98>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <bound method AttentionQKV.call of <transformer_attention.AttentionQKV object at 0x7f9aff380f98>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <bound method ApplyAttentionMask.call of <transformer_layers.ApplyAttentionMask object at 0x7f9aff388160>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method ApplyAttentionMask.call of <transformer_layers.ApplyAttentionMask object at 0x7f9aff388160>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method WeightNormDense.call of <transformer_layers.WeightNormDense object at 0x7f9afe2522b0>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method WeightNormDense.call of <transformer_layers.WeightNormDense object at 0x7f9afe2522b0>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method LayerNorm.call of <transformer_layers.LayerNorm object at 0x7f9aff380b00>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method LayerNorm.call of <transformer_layers.LayerNorm object at 0x7f9aff380b00>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method LayerNorm.call of <transformer_layers.LayerNorm object at 0x7f9aff380b00>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method LayerNorm.call of <transformer_layers.LayerNorm object at 0x7f9aff380b00>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <transformer_attention.MultiHeadAttention object at 0x7f9aff388550>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method MultiHeadAttention.call of <transformer_attention.MultiHeadAttention object at 0x7f9aff388550>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method WeightNormDense.call of <transformer_layers.WeightNormDense object at 0x7f9afdf5bb38>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method WeightNormDense.call of <transformer_layers.WeightNormDense object at 0x7f9afdf5bb38>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method WeightNormDense.call of <transformer_layers.WeightNormDense object at 0x7f9afdf5b128>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method WeightNormDense.call of <transformer_layers.WeightNormDense object at 0x7f9afdf5b128>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method WeightNormDense.call of <transformer_layers.WeightNormDense object at 0x7f9afdf6bdd8>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method WeightNormDense.call of <transformer_layers.WeightNormDense object at 0x7f9afdf6bdd8>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method MultiHeadProjection.call of <transformer_attention.MultiHeadProjection object at 0x7f9aff3886d8>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method MultiHeadProjection.call of <transformer_attention.MultiHeadProjection object at 0x7f9aff3886d8>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method AttentionQKV.call of <transformer_attention.AttentionQKV object at 0x7f9aff3888d0>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <bound method AttentionQKV.call of <transformer_attention.AttentionQKV object at 0x7f9aff3888d0>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <bound method ApplyAttentionMask.call of <transformer_layers.ApplyAttentionMask object at 0x7f9aff388a58>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method ApplyAttentionMask.call of <transformer_layers.ApplyAttentionMask object at 0x7f9aff388a58>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method WeightNormDense.call of <transformer_layers.WeightNormDense object at 0x7f9afdf6b5c0>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method WeightNormDense.call of <transformer_layers.WeightNormDense object at 0x7f9afdf6b5c0>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method TransformerFeedForward.call of <transformer.TransformerFeedForward object at 0x7f9aff388ba8>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method TransformerFeedForward.call of <transformer.TransformerFeedForward object at 0x7f9aff388ba8>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method LayerNorm.call of <transformer_layers.LayerNorm object at 0x7f9aff388d68>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method LayerNorm.call of <transformer_layers.LayerNorm object at 0x7f9aff388d68>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Stack.call of <transformer_layers.DenseStack object at 0x7f9aff388e80>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Stack.call of <transformer_layers.DenseStack object at 0x7f9aff388e80>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method TransformerDecoderBlock.call of <transformer.TransformerDecoderBlock object at 0x7f9aff394940>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method TransformerDecoderBlock.call of <transformer.TransformerDecoderBlock object at 0x7f9aff394940>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method LayerNorm.call of <transformer_layers.LayerNorm object at 0x7f9aff394b00>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method LayerNorm.call of <transformer_layers.LayerNorm object at 0x7f9aff394b00>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <transformer_attention.MultiHeadAttention object at 0x7f9aff394c18>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method MultiHeadAttention.call of <transformer_attention.MultiHeadAttention object at 0x7f9aff394c18>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method WeightNormDense.call of <transformer_layers.WeightNormDense object at 0x7f9afde30e48>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method WeightNormDense.call of <transformer_layers.WeightNormDense object at 0x7f9afde30e48>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method WeightNormDense.call of <transformer_layers.WeightNormDense object at 0x7f9afde30da0>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method WeightNormDense.call of <transformer_layers.WeightNormDense object at 0x7f9afde30da0>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method WeightNormDense.call of <transformer_layers.WeightNormDense object at 0x7f9afde30128>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method WeightNormDense.call of <transformer_layers.WeightNormDense object at 0x7f9afde30128>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method MultiHeadProjection.call of <transformer_attention.MultiHeadProjection object at 0x7f9aff394da0>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method MultiHeadProjection.call of <transformer_attention.MultiHeadProjection object at 0x7f9aff394da0>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method AttentionQKV.call of <transformer_attention.AttentionQKV object at 0x7f9aff394f98>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <bound method AttentionQKV.call of <transformer_attention.AttentionQKV object at 0x7f9aff394f98>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <bound method ApplyAttentionMask.call of <transformer_layers.ApplyAttentionMask object at 0x7f9aff39e160>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method ApplyAttentionMask.call of <transformer_layers.ApplyAttentionMask object at 0x7f9aff39e160>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method WeightNormDense.call of <transformer_layers.WeightNormDense object at 0x7f9afde308d0>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method WeightNormDense.call of <transformer_layers.WeightNormDense object at 0x7f9afde308d0>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method LayerNorm.call of <transformer_layers.LayerNorm object at 0x7f9aff394b00>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method LayerNorm.call of <transformer_layers.LayerNorm object at 0x7f9aff394b00>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method LayerNorm.call of <transformer_layers.LayerNorm object at 0x7f9aff394b00>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method LayerNorm.call of <transformer_layers.LayerNorm object at 0x7f9aff394b00>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <transformer_attention.MultiHeadAttention object at 0x7f9aff39e550>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method MultiHeadAttention.call of <transformer_attention.MultiHeadAttention object at 0x7f9aff39e550>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method WeightNormDense.call of <transformer_layers.WeightNormDense object at 0x7f9afddb1f98>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method WeightNormDense.call of <transformer_layers.WeightNormDense object at 0x7f9afddb1f98>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method WeightNormDense.call of <transformer_layers.WeightNormDense object at 0x7f9afe25b278>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method WeightNormDense.call of <transformer_layers.WeightNormDense object at 0x7f9afe25b278>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method WeightNormDense.call of <transformer_layers.WeightNormDense object at 0x7f9afddc09b0>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method WeightNormDense.call of <transformer_layers.WeightNormDense object at 0x7f9afddc09b0>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method MultiHeadProjection.call of <transformer_attention.MultiHeadProjection object at 0x7f9aff39e6d8>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method MultiHeadProjection.call of <transformer_attention.MultiHeadProjection object at 0x7f9aff39e6d8>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method AttentionQKV.call of <transformer_attention.AttentionQKV object at 0x7f9aff39e8d0>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <bound method AttentionQKV.call of <transformer_attention.AttentionQKV object at 0x7f9aff39e8d0>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <bound method ApplyAttentionMask.call of <transformer_layers.ApplyAttentionMask object at 0x7f9aff39ea58>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method ApplyAttentionMask.call of <transformer_layers.ApplyAttentionMask object at 0x7f9aff39ea58>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method WeightNormDense.call of <transformer_layers.WeightNormDense object at 0x7f9afdf5a6a0>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method WeightNormDense.call of <transformer_layers.WeightNormDense object at 0x7f9afdf5a6a0>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method TransformerFeedForward.call of <transformer.TransformerFeedForward object at 0x7f9aff39eba8>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method TransformerFeedForward.call of <transformer.TransformerFeedForward object at 0x7f9aff39eba8>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method LayerNorm.call of <transformer_layers.LayerNorm object at 0x7f9aff39ed68>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method LayerNorm.call of <transformer_layers.LayerNorm object at 0x7f9aff39ed68>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Stack.call of <transformer_layers.DenseStack object at 0x7f9aff39ee80>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Stack.call of <transformer_layers.DenseStack object at 0x7f9aff39ee80>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method TransformerDecoderBlock.call of <transformer.TransformerDecoderBlock object at 0x7f9aff3a8940>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method TransformerDecoderBlock.call of <transformer.TransformerDecoderBlock object at 0x7f9aff3a8940>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method LayerNorm.call of <transformer_layers.LayerNorm object at 0x7f9aff3a8b00>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method LayerNorm.call of <transformer_layers.LayerNorm object at 0x7f9aff3a8b00>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <transformer_attention.MultiHeadAttention object at 0x7f9aff3a8c18>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method MultiHeadAttention.call of <transformer_attention.MultiHeadAttention object at 0x7f9aff3a8c18>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method WeightNormDense.call of <transformer_layers.WeightNormDense object at 0x7f9aff39ee10>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method WeightNormDense.call of <transformer_layers.WeightNormDense object at 0x7f9aff39ee10>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method WeightNormDense.call of <transformer_layers.WeightNormDense object at 0x7f9afdc5d080>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method WeightNormDense.call of <transformer_layers.WeightNormDense object at 0x7f9afdc5d080>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method WeightNormDense.call of <transformer_layers.WeightNormDense object at 0x7f9afdc5d208>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method WeightNormDense.call of <transformer_layers.WeightNormDense object at 0x7f9afdc5d208>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method MultiHeadProjection.call of <transformer_attention.MultiHeadProjection object at 0x7f9aff3a8da0>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method MultiHeadProjection.call of <transformer_attention.MultiHeadProjection object at 0x7f9aff3a8da0>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method AttentionQKV.call of <transformer_attention.AttentionQKV object at 0x7f9aff3a8f98>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <bound method AttentionQKV.call of <transformer_attention.AttentionQKV object at 0x7f9aff3a8f98>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <bound method ApplyAttentionMask.call of <transformer_layers.ApplyAttentionMask object at 0x7f9aff333160>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method ApplyAttentionMask.call of <transformer_layers.ApplyAttentionMask object at 0x7f9aff333160>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method WeightNormDense.call of <transformer_layers.WeightNormDense object at 0x7f9afdc5d780>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method WeightNormDense.call of <transformer_layers.WeightNormDense object at 0x7f9afdc5d780>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method LayerNorm.call of <transformer_layers.LayerNorm object at 0x7f9aff3a8b00>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method LayerNorm.call of <transformer_layers.LayerNorm object at 0x7f9aff3a8b00>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method LayerNorm.call of <transformer_layers.LayerNorm object at 0x7f9aff3a8b00>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method LayerNorm.call of <transformer_layers.LayerNorm object at 0x7f9aff3a8b00>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <transformer_attention.MultiHeadAttention object at 0x7f9aff333550>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method MultiHeadAttention.call of <transformer_attention.MultiHeadAttention object at 0x7f9aff333550>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method WeightNormDense.call of <transformer_layers.WeightNormDense object at 0x7f9afdbc4f60>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method WeightNormDense.call of <transformer_layers.WeightNormDense object at 0x7f9afdbc4f60>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method WeightNormDense.call of <transformer_layers.WeightNormDense object at 0x7f9afdbc4c18>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method WeightNormDense.call of <transformer_layers.WeightNormDense object at 0x7f9afdbc4c18>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method WeightNormDense.call of <transformer_layers.WeightNormDense object at 0x7f9afdb2be10>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method WeightNormDense.call of <transformer_layers.WeightNormDense object at 0x7f9afdb2be10>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method MultiHeadProjection.call of <transformer_attention.MultiHeadProjection object at 0x7f9aff3336d8>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method MultiHeadProjection.call of <transformer_attention.MultiHeadProjection object at 0x7f9aff3336d8>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method AttentionQKV.call of <transformer_attention.AttentionQKV object at 0x7f9aff3338d0>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <bound method AttentionQKV.call of <transformer_attention.AttentionQKV object at 0x7f9aff3338d0>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <bound method ApplyAttentionMask.call of <transformer_layers.ApplyAttentionMask object at 0x7f9aff333a58>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method ApplyAttentionMask.call of <transformer_layers.ApplyAttentionMask object at 0x7f9aff333a58>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method WeightNormDense.call of <transformer_layers.WeightNormDense object at 0x7f9afdaf5da0>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method WeightNormDense.call of <transformer_layers.WeightNormDense object at 0x7f9afdaf5da0>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method TransformerFeedForward.call of <transformer.TransformerFeedForward object at 0x7f9aff333ba8>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method TransformerFeedForward.call of <transformer.TransformerFeedForward object at 0x7f9aff333ba8>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method LayerNorm.call of <transformer_layers.LayerNorm object at 0x7f9aff333d68>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method LayerNorm.call of <transformer_layers.LayerNorm object at 0x7f9aff333d68>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Stack.call of <transformer_layers.DenseStack object at 0x7f9aff333e80>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Stack.call of <transformer_layers.DenseStack object at 0x7f9aff333e80>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method TransformerDecoderBlock.call of <transformer.TransformerDecoderBlock object at 0x7f9aff33d940>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method TransformerDecoderBlock.call of <transformer.TransformerDecoderBlock object at 0x7f9aff33d940>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method LayerNorm.call of <transformer_layers.LayerNorm object at 0x7f9aff33db00>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method LayerNorm.call of <transformer_layers.LayerNorm object at 0x7f9aff33db00>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <transformer_attention.MultiHeadAttention object at 0x7f9aff33dc18>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method MultiHeadAttention.call of <transformer_attention.MultiHeadAttention object at 0x7f9aff33dc18>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method WeightNormDense.call of <transformer_layers.WeightNormDense object at 0x7f9afd9cd748>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method WeightNormDense.call of <transformer_layers.WeightNormDense object at 0x7f9afd9cd748>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method WeightNormDense.call of <transformer_layers.WeightNormDense object at 0x7f9afd9cd8d0>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method WeightNormDense.call of <transformer_layers.WeightNormDense object at 0x7f9afd9cd8d0>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method WeightNormDense.call of <transformer_layers.WeightNormDense object at 0x7f9afd9cdd30>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method WeightNormDense.call of <transformer_layers.WeightNormDense object at 0x7f9afd9cdd30>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method MultiHeadProjection.call of <transformer_attention.MultiHeadProjection object at 0x7f9aff33dda0>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method MultiHeadProjection.call of <transformer_attention.MultiHeadProjection object at 0x7f9aff33dda0>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method AttentionQKV.call of <transformer_attention.AttentionQKV object at 0x7f9aff33df98>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <bound method AttentionQKV.call of <transformer_attention.AttentionQKV object at 0x7f9aff33df98>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <bound method ApplyAttentionMask.call of <transformer_layers.ApplyAttentionMask object at 0x7f9aff346160>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method ApplyAttentionMask.call of <transformer_layers.ApplyAttentionMask object at 0x7f9aff346160>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method WeightNormDense.call of <transformer_layers.WeightNormDense object at 0x7f9afd9cd588>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method WeightNormDense.call of <transformer_layers.WeightNormDense object at 0x7f9afd9cd588>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method LayerNorm.call of <transformer_layers.LayerNorm object at 0x7f9aff33db00>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method LayerNorm.call of <transformer_layers.LayerNorm object at 0x7f9aff33db00>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method LayerNorm.call of <transformer_layers.LayerNorm object at 0x7f9aff33db00>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method LayerNorm.call of <transformer_layers.LayerNorm object at 0x7f9aff33db00>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <transformer_attention.MultiHeadAttention object at 0x7f9aff346550>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method MultiHeadAttention.call of <transformer_attention.MultiHeadAttention object at 0x7f9aff346550>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method WeightNormDense.call of <transformer_layers.WeightNormDense object at 0x7f9afd9de8d0>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method WeightNormDense.call of <transformer_layers.WeightNormDense object at 0x7f9afd9de8d0>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method WeightNormDense.call of <transformer_layers.WeightNormDense object at 0x7f9afd9deeb8>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method WeightNormDense.call of <transformer_layers.WeightNormDense object at 0x7f9afd9deeb8>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method WeightNormDense.call of <transformer_layers.WeightNormDense object at 0x7f9afd9e9588>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method WeightNormDense.call of <transformer_layers.WeightNormDense object at 0x7f9afd9e9588>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method MultiHeadProjection.call of <transformer_attention.MultiHeadProjection object at 0x7f9aff3466d8>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method MultiHeadProjection.call of <transformer_attention.MultiHeadProjection object at 0x7f9aff3466d8>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method AttentionQKV.call of <transformer_attention.AttentionQKV object at 0x7f9aff3468d0>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <bound method AttentionQKV.call of <transformer_attention.AttentionQKV object at 0x7f9aff3468d0>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <bound method ApplyAttentionMask.call of <transformer_layers.ApplyAttentionMask object at 0x7f9aff346a58>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method ApplyAttentionMask.call of <transformer_layers.ApplyAttentionMask object at 0x7f9aff346a58>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method WeightNormDense.call of <transformer_layers.WeightNormDense object at 0x7f9afd9d1da0>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method WeightNormDense.call of <transformer_layers.WeightNormDense object at 0x7f9afd9d1da0>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method TransformerFeedForward.call of <transformer.TransformerFeedForward object at 0x7f9aff346ba8>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method TransformerFeedForward.call of <transformer.TransformerFeedForward object at 0x7f9aff346ba8>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method LayerNorm.call of <transformer_layers.LayerNorm object at 0x7f9aff346d68>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method LayerNorm.call of <transformer_layers.LayerNorm object at 0x7f9aff346d68>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Stack.call of <transformer_layers.DenseStack object at 0x7f9aff346e80>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Stack.call of <transformer_layers.DenseStack object at 0x7f9aff346e80>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method TransformerDecoderBlock.call of <transformer.TransformerDecoderBlock object at 0x7f9aff352940>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method TransformerDecoderBlock.call of <transformer.TransformerDecoderBlock object at 0x7f9aff352940>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method LayerNorm.call of <transformer_layers.LayerNorm object at 0x7f9aff352b00>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method LayerNorm.call of <transformer_layers.LayerNorm object at 0x7f9aff352b00>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <transformer_attention.MultiHeadAttention object at 0x7f9aff352c18>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method MultiHeadAttention.call of <transformer_attention.MultiHeadAttention object at 0x7f9aff352c18>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method WeightNormDense.call of <transformer_layers.WeightNormDense object at 0x7f9afd7d1400>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method WeightNormDense.call of <transformer_layers.WeightNormDense object at 0x7f9afd7d1400>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method WeightNormDense.call of <transformer_layers.WeightNormDense object at 0x7f9afd7d1128>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method WeightNormDense.call of <transformer_layers.WeightNormDense object at 0x7f9afd7d1128>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method WeightNormDense.call of <transformer_layers.WeightNormDense object at 0x7f9afd7d1630>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method WeightNormDense.call of <transformer_layers.WeightNormDense object at 0x7f9afd7d1630>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method MultiHeadProjection.call of <transformer_attention.MultiHeadProjection object at 0x7f9aff352da0>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method MultiHeadProjection.call of <transformer_attention.MultiHeadProjection object at 0x7f9aff352da0>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method AttentionQKV.call of <transformer_attention.AttentionQKV object at 0x7f9aff352f98>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <bound method AttentionQKV.call of <transformer_attention.AttentionQKV object at 0x7f9aff352f98>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <bound method ApplyAttentionMask.call of <transformer_layers.ApplyAttentionMask object at 0x7f9aff35a160>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method ApplyAttentionMask.call of <transformer_layers.ApplyAttentionMask object at 0x7f9aff35a160>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method WeightNormDense.call of <transformer_layers.WeightNormDense object at 0x7f9afd7d1e80>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method WeightNormDense.call of <transformer_layers.WeightNormDense object at 0x7f9afd7d1e80>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method LayerNorm.call of <transformer_layers.LayerNorm object at 0x7f9aff352b00>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method LayerNorm.call of <transformer_layers.LayerNorm object at 0x7f9aff352b00>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method LayerNorm.call of <transformer_layers.LayerNorm object at 0x7f9aff352b00>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method LayerNorm.call of <transformer_layers.LayerNorm object at 0x7f9aff352b00>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <transformer_attention.MultiHeadAttention object at 0x7f9aff35a550>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method MultiHeadAttention.call of <transformer_attention.MultiHeadAttention object at 0x7f9aff35a550>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method WeightNormDense.call of <transformer_layers.WeightNormDense object at 0x7f9afd7e5400>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method WeightNormDense.call of <transformer_layers.WeightNormDense object at 0x7f9afd7e5400>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method WeightNormDense.call of <transformer_layers.WeightNormDense object at 0x7f9afd7e51d0>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method WeightNormDense.call of <transformer_layers.WeightNormDense object at 0x7f9afd7e51d0>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method WeightNormDense.call of <transformer_layers.WeightNormDense object at 0x7f9afd7d52e8>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method WeightNormDense.call of <transformer_layers.WeightNormDense object at 0x7f9afd7d52e8>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method MultiHeadProjection.call of <transformer_attention.MultiHeadProjection object at 0x7f9aff35a6d8>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method MultiHeadProjection.call of <transformer_attention.MultiHeadProjection object at 0x7f9aff35a6d8>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method AttentionQKV.call of <transformer_attention.AttentionQKV object at 0x7f9aff35a8d0>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <bound method AttentionQKV.call of <transformer_attention.AttentionQKV object at 0x7f9aff35a8d0>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <bound method ApplyAttentionMask.call of <transformer_layers.ApplyAttentionMask object at 0x7f9aff35aa58>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method ApplyAttentionMask.call of <transformer_layers.ApplyAttentionMask object at 0x7f9aff35aa58>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method WeightNormDense.call of <transformer_layers.WeightNormDense object at 0x7f9afd6dcda0>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method WeightNormDense.call of <transformer_layers.WeightNormDense object at 0x7f9afd6dcda0>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method TransformerFeedForward.call of <transformer.TransformerFeedForward object at 0x7f9aff35aba8>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method TransformerFeedForward.call of <transformer.TransformerFeedForward object at 0x7f9aff35aba8>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method LayerNorm.call of <transformer_layers.LayerNorm object at 0x7f9aff35ad68>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method LayerNorm.call of <transformer_layers.LayerNorm object at 0x7f9aff35ad68>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Stack.call of <transformer_layers.DenseStack object at 0x7f9aff35ae80>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Stack.call of <transformer_layers.DenseStack object at 0x7f9aff35ae80>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method EmbeddingTranspose.call of <transformer_layers.EmbeddingTranspose object at 0x7f9b00633ef0>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <bound method EmbeddingTranspose.call of <transformer_layers.EmbeddingTranspose object at 0x7f9b00633ef0>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/ops/losses/losses_impl.py:121: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    }
   ],
   "source": [
    "# Dataset related parameters\n",
    "vocab_size = len(vocab)\n",
    "ilength = 400 # Length of the article\n",
    "olength  = 100 # Length of the summaries\n",
    "\n",
    "# Model related parameters, feel free to modify these.\n",
    "n_layers = 6\n",
    "d_model  = 120\n",
    "d_filter = 416\n",
    "\n",
    "# model = TransformerTrainer(vocab_size, d_model, ilength, olength, n_layers, d_filter)\n",
    "\n",
    "model = TransformerTrainer(vocab_size, d_model, ilength, olength, n_layers, d_filter,\n",
    "                           learning_rate=1e-3, dropout=0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "B4w69h1OZ4a6"
   },
   "source": [
    "# Training the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nLFtXtV8Z4a_"
   },
   "source": [
    "Your objective is to train the Language on the dataset you are provided to reach a **loss <= 4.50**\n",
    "\n",
    "Careful: we will be testing this loss on an unreleased test set, so make sure to evaluate properly on a validation set and not overfit.\n",
    "\n",
    "You must save the model you want us to test under: models/final_transformer_summarization (the .index, .meta and .data files)\n",
    "\n",
    "**Advice**:\n",
    "- It should be possible to attain loss <= 4.50 with the model dimensions we've specified (n_layers=6, d_model=104, d_filter=416), but you can tune these hyperparameters. Increasing d_model will yield better model, at the cost of longer training time.\n",
    "- You should try tuning the learning rate, as well as what optimizer you use.\n",
    "- You might need to train for a few (up to 2 hours) to obtain our expected loss. Remember to tune your hyperparameters first, once you find ones that work well, let it train for longer.\n",
    "\n",
    "**Dataset**: as in the previous notebook, make sure the dataset files are in the `dataset` folder. These can be found on the Google Drive.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 33681,
     "status": "ok",
     "timestamp": 1585772854102,
     "user": {
      "displayName": "Keisuke Watanabe",
      "photoUrl": "",
      "userId": "04038047229892014346"
     },
     "user_tz": 420
    },
    "id": "OSPjAYzbZ4bA",
    "outputId": "1d46ebb0-7301-4061-f463-4b49e6ec354b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(61055, 1558)"
      ]
     },
     "execution_count": 8,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(root_folder+\"dataset/summarization_dataset_preprocessed.json\", \"r\") as f:\n",
    "\n",
    "    dataset = json.load(f)\n",
    "\n",
    "# We load the dataset, and split it into 2 sub-datasets based on if they are training or validation.\n",
    "# Feel free to split this dataset another way, but remember, a validation set is important, to have an idea of \n",
    "# the amount of overfitting that has occurred!\n",
    "\n",
    "d_train = [d for d in dataset if d['cut'] == 'training']\n",
    "d_valid = [d for d in dataset if d['cut'] == 'evaluation']\n",
    "\n",
    "len(d_train), len(d_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 490
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 31038,
     "status": "ok",
     "timestamp": 1585772854103,
     "user": {
      "displayName": "Keisuke Watanabe",
      "photoUrl": "",
      "userId": "04038047229892014346"
     },
     "user_tz": 420
    },
    "id": "dhUEgN-gZ4bF",
    "outputId": "ba1796d2-bf51-470c-f939-77a53162a365"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tbilisi, Georgia (CNN)Police have shot and killed a white tiger that killed a man Wednesday in Tbilisi, Georgia, a Ministry of Internal Affairs representative said, after severe flooding allowed hundreds of wild animals to escape the city zoo. \n",
      "The tiger attack happened at a warehouse in the city center. The animal had been unaccounted for since the weekend floods destroyed the zoo premises.\n",
      "The man killed, who was 43, worked in a company based in the warehouse, the Ministry of Internal Affairs said. Doctors said he was attacked in the throat and died before reaching the hospital. \n",
      "Experts are still searching the warehouse, the ministry said, adding that earlier reports that the tiger had injured a second man were unfounded. \n",
      "The zoo administration said Wednesday that another tiger was still missing. It was unable to confirm if the creature was dead or had escaped alive.\n",
      "Georgian Prime Minister Irakli Garibashvili apologized to the public, saying he had been misinformed by the zoo's management when he'd previously said there were no more dangerous animals on the run.\n",
      "City residents were urged to stay indoors for their own safety in the immediate aftermath of the floods. Volunteers have since been helping city workers with the cleanup operation.\n",
      "At least 19 people died in the flooding, according to Civil Georgia, a news website run by the nongovernmental organization United Nations Association of Georgia. Six more remained missing, it said Tuesday, citing the State Security and Crisis Management Council.\n",
      "Meanwhile, the zoo lost about half of its 600 animals, including lions, tigers, bears and wolves, in the natural disaster. \n",
      "Some animals have since been recaptured, Civil Georgia reported. Others died in the floods or have been killed by police as they scour the streets for escapees.\n",
      "Russian state news outlet RT.com  that an African penguin had made it 60 kilometers (37 miles) downriver from Tbilisi before being caught alive in a dragnet on the border with Azerbaijan. \n",
      "Video from the city showed a large crocodile being restrained by rescuers, as well as a hippopotamus standing in floodwaters, looking confused.\n",
      "The latter was eventually cornered in a city square before being tranquilized and recaptured.\n",
      "One terrified bear escaped the flood by perching on a window ledge.\n",
      "Video footage also showed devastation across swaths of the Georgian capital, where flash floods swept away roads, at least one house and many trees. The corpses of dead animals could be seen amid the wreckage.\n",
      "The problems began before midnight Saturday when heavy rainfall turned the Vere River, usually little more than a stream through the center of Tbilisi, into a raging torrent, according to Civil Georgia.\n",
      "Images on Tbilisi City Hall's Facebook page showed roads washed out, hillsides collapsed and vehicles tossed about like toys. Rescue workers carried people on their shoulders through waist-high water.\n",
      "Garibashvili extended his condolences Tuesday to the families of those killed in the flooding.\n",
      "He also proposed the creation of a park in the zoo premises to honor those lost. \"It will be a park of solidarity, a symbol of our unity, selflessness, and mutual support,\" he said in a statement on his website.\n",
      "President Georgi Margvelashvili earlier said the capital's mayoral office would help those who had lost out financially as a result of the floods.\n",
      "\"The situation is difficult, but it can be handled except for the fact that we cannot bring back those who died,\" he said.\n",
      "According to the World Wildlife Fund, as few as 3,200 tigers exist in the wild today.\n",
      "\n",
      "Journalist Eka Kadagishvili reported from Tbilisi, and Laura Smith-Spark wrote from London. CNN's Kimberly Hutcherson contributed to this report.\n",
      "=======================\n",
      "=======================\n",
      "Police have shot dead a tiger that killed a man in Tbilisi, Georgia, a government official says, after zoo animals escaped in weekend flooding.\n"
     ]
    }
   ],
   "source": [
    "# An example (article, summary) pair in the training data:\n",
    "\n",
    "print(d_train[145]['story'])\n",
    "print(\"=======================\\n=======================\")\n",
    "print(d_train[145]['summary'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Gn5bLgiTZ4bY"
   },
   "source": [
    "Similarly to the previous assignment, we create a function to get a random batch to train on, given a dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nQrIBq41Z4bf"
   },
   "outputs": [],
   "source": [
    "def build_batch(dataset, batch_size):\n",
    "    indices = list(np.random.randint(0, len(dataset), size=batch_size))\n",
    "    \n",
    "    batch = [dataset[i] for i in indices]\n",
    "    batch_input = np.array([a['input'] for a in batch])\n",
    "    batch_input_mask = np.array([a['input_mask'] for a in batch])\n",
    "    batch_output = np.array([a['output'] for a in batch])\n",
    "    batch_output_mask = np.array([a['output_mask'] for a in batch])\n",
    "    \n",
    "    return batch_input, batch_input_mask, batch_output, batch_output_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 420
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 15189974,
     "status": "ok",
     "timestamp": 1585794107566,
     "user": {
      "displayName": "Keisuke Watanabe",
      "photoUrl": "",
      "userId": "04038047229892014346"
     },
     "user_tz": 420
    },
    "id": "eeZPxPYnZ4bp",
    "outputId": "b7962fff-dac4-4d86-9c93-ea03482b0c85"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1\n",
      "training loss: 5.076408679231806\n",
      "Validation loss: 4.7431746\n",
      "epoch: 2\n",
      "training loss: 4.457381522960178\n",
      "Validation loss: 4.4797544\n",
      "epoch: 3\n",
      "training loss: 4.23978823345785\n",
      "Validation loss: 4.321268\n",
      "epoch: 4\n",
      "training loss: 4.108531207309229\n",
      "Validation loss: 4.3264565\n",
      "epoch: 5\n",
      "training loss: 4.0155635699474805\n",
      "Validation loss: 4.2600136\n",
      "epoch: 6\n",
      "training loss: 3.935874325017093\n",
      "Validation loss: 4.346153\n",
      "epoch: 7\n",
      "training loss: 3.865306239315218\n",
      "Validation loss: 4.1450486\n",
      "epoch: 8\n",
      "training loss: 3.8006708083315717\n",
      "Validation loss: 4.053105\n"
     ]
    }
   ],
   "source": [
    "# Skeleton code, as in the previous notebook.\n",
    "# Write code training code and save your best performing model on the\n",
    "# validation set. We will be testing the loss on a held-out test dataset.\n",
    "batch_size = 2\n",
    "batch_num = len(d_train) // batch_size\n",
    "with tf.Session() as sess:\n",
    "    # This is how you randomly initialize the Transformer weights.\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    train_loss = 0\n",
    "    for epoch in range(8):\n",
    "        train_loss = 0\n",
    "        print(\"epoch:\", epoch + 1)\n",
    "        for i in range(batch_num):\n",
    "            batch_input, batch_input_mask, batch_output, batch_output_mask = build_batch(d_train, batch_size)\n",
    "            feed = {model.source_sequence: batch_input, model.target_sequence: batch_output,\n",
    "                                  model.encoder_mask: batch_input_mask, model.decoder_mask: batch_output_mask}\n",
    "\n",
    "            loss, _, step = sess.run([model.loss, model.train_op, model.global_step], feed_dict=feed)\n",
    "            train_loss += loss\n",
    "        print(\"training loss:\", train_loss / batch_num)\n",
    "\n",
    "        e_input, e_input_mask, e_output, e_output_mask = build_batch(d_valid, 200)\n",
    "        feed = {model.source_sequence: e_input, model.target_sequence: e_output,\n",
    "                                          model.encoder_mask: e_input_mask, model.decoder_mask: e_output_mask}\n",
    "        valid_loss = sess.run(model.loss, feed_dict=feed)\n",
    "        print(\"Validation loss:\", valid_loss)\n",
    "\n",
    "    # This is how you save model weights into a file\n",
    "    model.saver.save(sess, root_folder+\"models/final_transformer_summarization\")\n",
    "\n",
    "\n",
    "    # This is how you restore a model previously saved\n",
    "    # model.saver.restore(sess, root_folder+\"models/final_transformer_summarization\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fousC2uEZ4bx"
   },
   "source": [
    "# Using the Summarization model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0o68cjW5Z4bz"
   },
   "source": [
    "Now that you have trained a Transformer to perform Summarization, we will use the model on news articles from the wild.\n",
    "\n",
    "The three subsections below explore what the model has learned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7X4fG3-7Z4b1"
   },
   "outputs": [],
   "source": [
    "# Put the file path to your best performing model in the string below.\n",
    "\n",
    "model_file = root_folder+\"models/final_transformer_summarization\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZI0f-X4lZ4cX"
   },
   "source": [
    "## The validation loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vg_0PWfPZ4cZ"
   },
   "source": [
    "Measure the validation loss of your model. This part could be used, as in our previous notebook, in deciding what is a likely, vs. unlikely summary for an article.\n",
    "\n",
    "We will use the code here with the unreleased test-set to evaluate your model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 50
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 4949,
     "status": "ok",
     "timestamp": 1585794852675,
     "user": {
      "displayName": "Keisuke Watanabe",
      "photoUrl": "",
      "userId": "04038047229892014346"
     },
     "user_tz": 420
    },
    "id": "VXRuBjIvZ4cb",
    "outputId": "5119cf6b-4fcb-4272-c457-20d34afc50ad"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from /content/gdrive/My Drive/Colab Notebooks/cs182/CS182_HW03/models/final_transformer_summarization\n",
      "Validation loss: 4.127721\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    model.saver.restore(sess, model_file)\n",
    "\n",
    "    e_input, e_input_mask, e_output, e_output_mask = build_batch(d_valid, 200)\n",
    "    feed = {model.source_sequence: e_input, model.target_sequence: e_output,\n",
    "                                      model.encoder_mask: e_input_mask, model.decoder_mask: e_output_mask}\n",
    "    valid_loss = sess.run(model.loss, feed_dict=feed)\n",
    "    print(\"Validation loss:\", valid_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "UMamsFG4Z4cf"
   },
   "source": [
    "## Generating an article's summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ORs-KZuzZ4ci"
   },
   "source": [
    "This model we have built is meant to be used to generate summaries for new articles we do not have summaries for.\n",
    "We got a [news article](https://www.chicagotribune.com/news/local/breaking/ct-met-officer-shot-20190309-story.html) from the Chicago Tribune about a police shooting, and want to use our model to produce a summary.\n",
    "\n",
    "As you will see, our model is still limited in its ability, and will most likely not produce a perfect summary, however, with more data and training, this model would be able to produce good summaries.\n",
    "The article you produce should look like broken English sentences, but should roughly correspond to the article."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 87
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 8142,
     "status": "ok",
     "timestamp": 1585794492710,
     "user": {
      "displayName": "Keisuke Watanabe",
      "photoUrl": "",
      "userId": "04038047229892014346"
     },
     "user_tz": 420
    },
    "id": "f96rnV6pZ4cj",
    "outputId": "702215cc-f159-48ca-f95c-219c43bd4933"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from /content/gdrive/My Drive/Colab Notebooks/cs182/CS182_HW03/models/final_transformer_summarization\n",
      "The final summary:\n",
      "<unk>  ↑↑  roinc  ↑↑  juninjun ,  a↑  chicagoro policee officer , who was was shot shot in in the the back routine of , a police police spokesman official said said  ↑↑ thursday  .↑ \" the  ↑↑  chelrochele  \"↑  ak↑ri w↑w w↑w w↑w in↑ ,  ↑↑ chicago  ,\n"
     ]
    }
   ],
   "source": [
    "article_text = \"A 34-year-old Chicago police officer has been shot in the shoulder during the execution of a search warrant in the Humboldt Park neighborhood, police say. The alleged shooter, a 19-year-old woman, was in custody. The shooting happened about 7:20 p.m. in the 2700 block of West Potomac Avenue, police said. The officer, part of the Grand Central District tactical unit, was taken to Stroger Hospital. While officers were serving a \\\"typical\\\" search warrant for \\\"narcotics and illegal weapons\\\" and were attempting to reach a rear door, \\\"a shot was fired,\\\" striking the tactical officer in the shoulder, said Chicago police Superintendent Eddie Johnson during a news briefing outside the hospital. He said the officer, who has about four or five years on the job, was \\\"stable\\\" but in critical condition. \\\"His family is here,\\\" Johnson said. \\\"He’s talking a lot and just wants the ordeal to be over.\\\" He said this incident serves as just another reminder of how dangerous a police officer’s job is. At the scene of the shooting, crime tape closed Potomac from Washtenaw Avenue to California Avenue and encompassed the alley west of the brick apartment building, south of Potomac. Dozens of officers stood in the alley, while even more walked up and down the street. Neighbors gathered at the edge of the yellow tape on the sidewalk along California and watched them work. Standing next to a man, a woman talked to police in the crime scene, across the street. \\\"We're not under arrest? We can go?\\\" the woman checked with officers. They told her she could go, and she and the man walked underneath the yellow tape and out of the crime scene.\"\n",
    "input_length = 400\n",
    "output_length = 100\n",
    "\n",
    "# Process the capitalization with the preprocess_capitalization of the capita package.\n",
    "article_text = capita.preprocess_capitalization(article_text)\n",
    "\n",
    "# Numerize the tokens of the processed text using the loaded sentencepiece model.\n",
    "numerized = sp.EncodeAsIds(article_text)\n",
    "# Pad the sequence and keep the mask of the input\n",
    "padded, mask = pad_sequence(numerized, pad_index, input_length)\n",
    "\n",
    "# Making the news article into a batch of size one, to be fed to the neural network.\n",
    "encoder_input = np.array([padded])\n",
    "encoder_mask = np.array([mask])\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    model.saver.restore(sess, model_file)\n",
    "\n",
    "    decoded_so_far = [0]\n",
    "    \n",
    "    for j in range(output_length):\n",
    "        padded_decoder_input, decoder_mask = pad_sequence(decoded_so_far, pad_index, output_length)\n",
    "        padded_decoder_input = [padded_decoder_input]\n",
    "        decoder_mask = [decoder_mask]\n",
    "        # print(\"========================\")\n",
    "        # print(padded_decoder_input)\n",
    "        # Use the model to find the distrbution over the vocabulary for the next word\n",
    "        feed = {model.source_sequence: encoder_input, model.target_sequence: padded_decoder_input, model.encoder_mask: encoder_input,model.decoder_mask: decoder_mask}\n",
    "        logits = sess.run([model.decoded_logits], feed_dict=feed)[0]\n",
    "        \n",
    "        chosen_words = np.argmax(logits, axis=2)  # Take the argmax, getting the most likely next word\n",
    "        decoded_so_far.append(int(chosen_words[0, j])) # We add it to the summary so far\n",
    "\n",
    "\n",
    "print(\"The final summary:\")\n",
    "print(\"\".join([vocab[i] for i in decoded_so_far]).replace(\"▁\", \" \"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qyDCOeImZ4cq"
   },
   "source": [
    "## Word vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tMfyQNolZ4cq"
   },
   "source": [
    "The model we train learns word representations for each word in our vocabulary. A word represention is a vector of **dim** size.\n",
    "\n",
    "It is common in NLP to inspect the word vectors, as some properties of language often appear in the embedding structure.\n",
    "\n",
    "\n",
    "We are going to load the word embeddings learned by our model, and inspect it.\n",
    "Because our network was not trained for long, we are going for the simplest patterns, but if we let the network train longer, it learns more complex, semantic patterns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 67
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 4309,
     "status": "ok",
     "timestamp": 1585794512296,
     "user": {
      "displayName": "Keisuke Watanabe",
      "photoUrl": "",
      "userId": "04038047229892014346"
     },
     "user_tz": 420
    },
    "id": "skDUFxVGZ4cv",
    "outputId": "01c68d79-3457-45ba-d949-9612f6b826c6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from /content/gdrive/My Drive/Colab Notebooks/cs182/CS182_HW03/models/final_transformer_summarization\n",
      "The embedding matrix has shape: (10000, 120)\n",
      "The vocabulary has length: 10000\n"
     ]
    }
   ],
   "source": [
    "# We help you load the matrix, as it is hidden within the Transformer structure.\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    model.saver.restore(sess, model_file)\n",
    "    E = sess.run(model.model.encoder.embedding_layer.embedding.embeddings)\n",
    "\n",
    "print(\"The embedding matrix has shape:\", E.shape)\n",
    "print(\"The vocabulary has length:\", len(vocab))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FKgmjMwnZ4cz"
   },
   "source": [
    "Pronouns serve very similar purposes, therefore we should expect the representation of \"he\" and \"she\" to be similar, and have cosine similarity.\n",
    "\n",
    "- **TODO**:  Find the cosine similarity between the vectors that represent words \"she\" and \"he\".\n",
    "- **TODO**:  Find the cosine similarity between the vectors that represent words \"more\" and \"less\".\n",
    "\n",
    "We can contrast that with the cosine similarity to a random, non-related word, like \"ball\", or \"gorilla\".\n",
    "- **TODO**: Compute the cosine similarity between \"she\" and \"ball\".\n",
    "- **TODO**: Compute the cosine similarity between \"more\" and \"protest\".\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 84
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 558,
     "status": "ok",
     "timestamp": 1585794513597,
     "user": {
      "displayName": "Keisuke Watanabe",
      "photoUrl": "",
      "userId": "04038047229892014346"
     },
     "user_tz": 420
    },
    "id": "8YuRuNSkZ4c1",
    "outputId": "37e9b390-f150-4734-c1e4-f35fe60d302a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "she  vs.  he similarity: 0.8099722\n",
      "more  vs.  less similarity: 0.6066089\n",
      "she  vs.  ball similarity: 0.0837916\n",
      "more  vs.  gorilla similarity: -0.0117558\n"
     ]
    }
   ],
   "source": [
    "def cosine_sim(v1, v2):\n",
    "    # TODO: Implement the cosine similarity of 2 vectors. Careful: the words might not have unit norm.\n",
    "    return np.dot(v1, v2) / (np.linalg.norm(v1) * np.linalg.norm(v2))\n",
    "\n",
    "for w1, w2 in [(\"she\", \"he\"), (\"more\", \"less\"), (\"she\", \"ball\"), (\"more\", \"gorilla\")]:\n",
    "    w1_index = vocab.index('▁'+w1) # The index of the first  word in our vocabulary\n",
    "    w2_index = vocab.index('▁'+w2) # The index of the second word in our vocabulary\n",
    "    w1_vec = E[w1_index] # Get the embedding vector of the first  word\n",
    "    w2_vec = E[w2_index] # Get the embedding vector of the second word\n",
    "    \n",
    "    print(w1,\" vs. \", w2, \"similarity:\",cosine_sim(w1_vec, w2_vec))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zezJanEMZ4c4"
   },
   "source": [
    "These effects are unfortunately small, as we have only trained the network on a few hours on a few thousand articles.\n",
    "However, the same model trained for longer on more data exhibits many interesting semantic and syntactic patterns, such as:\n",
    "\n",
    "- Words vectors with high cosine similarity usually represent words that have semantic similarity (such as duck and pigeon)\n",
    "- Analogies can occur, a famous case is that of: woman - man + king ≈ queen. Or france - paris + rome ≈ italy.\n",
    "\n",
    "- Looking at top-k similar words can help find synonyms.\n",
    "\n",
    "To read examples of more complex patterns that appear in word embedding spaces, read [this blog](https://explosion.ai/blog/sense2vec-with-spacy). To play with a live demo and try similarities on rich word embeddings, [go here.](https://explosion.ai/demos/sense2vec)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "WQrV-Gd1Z4Y7"
   ],
   "name": "2 Summarization.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "cs182-ass3",
   "language": "python",
   "name": "cs182-ass3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
